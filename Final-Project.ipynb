{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612fc418-cd31-4623-8f25-289f5cc5036d",
   "metadata": {},
   "source": [
    "# Final Project for INFO 6350\n",
    "## Net ID: yz2685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55973c51-65a9-4f7c-a387-f5a05648497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our libraries\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import simplejson as json\n",
    "from urllib.request import Request, urlopen\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76d60a5-27d4-49e9-a6f7-f75b52d4bd37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the base url needed to create the file url.\n",
    "base_url = r\"https://www.sec.gov\"\n",
    "\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36'\n",
    "}\n",
    "# content = requests.get(documents_url, headers=header)\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721deda-2829-42d9-bee4-99731ed795ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdc364f-fa4e-4a93-9f36-fa63d523f5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>cik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aapl</td>\n",
       "      <td>320193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>msft</td>\n",
       "      <td>789019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>googl</td>\n",
       "      <td>1652044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amzn</td>\n",
       "      <td>1018724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsla</td>\n",
       "      <td>1318605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company      cik\n",
       "0    aapl   320193\n",
       "1    msft   789019\n",
       "2   googl  1652044\n",
       "3    amzn  1018724\n",
       "4    tsla  1318605"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cik = pd.read_csv('cik.csv').fillna(value = 0).head(10)\n",
    "list_cik.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcbe9bb-b4f7-478c-9246-4bff6381778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965a351-d6c0-476d-9991-4bce266a5c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ae202-aa7c-4e63-ab82-cfe7b314c4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ae032-b605-4db8-9509-4afd77bacccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650c34d-ee75-4d0f-b8fe-75cf9e08cd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0297d2b2-3106-4750-b5cf-959a67cd96da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scraping the SEC Query Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd37037-e388-42bf-b68a-0e1740119b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0541d997-e211-4f1d-b192-3753ab39411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base URL for the SEC EDGAR browser\n",
    "endpoint = r\"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "cik = '1018724' # Amazon\n",
    "company = 'amzn'\n",
    "ciks = []\n",
    "risks = []\n",
    "years = []\n",
    "urls = []\n",
    "companies = []\n",
    "\n",
    "\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d513e4-ad48-44c4-9374-6e4c9dac2af4",
   "metadata": {},
   "source": [
    "### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3f9898-520c-4eee-a7e6-cf03b963d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the links to the 10k reports \n",
    "def get10kPages(url):\n",
    "    response = requests.get(url = url, headers=header)\n",
    "    soup10k = BeautifulSoup(response.content, 'html.parser')\n",
    "    # print(response)\n",
    "    # print(response.url)\n",
    "    return response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edce853a-d2bf-4fce-8143-5c6de0b09456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get10kLinks(url, list_of_10ks):\n",
    "    response = requests.get(url = url, headers=header)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # for a in soup.find_all('a', href=True):\n",
    "        # url = a['href']\n",
    "        # print(url)\n",
    "        \n",
    "    suffix = \"htm\";\n",
    "\n",
    "    tables = soup.find('table')\n",
    "    rows = tables.find_all('tr')\n",
    "    if len(rows) > 0:\n",
    "        row10k = rows[1] # row 1 has link to 10k report\n",
    "        # print(row10k)\n",
    "        for a in row10k.find_all('a', href=True):\n",
    "            url = a['href']\n",
    "            if url.endswith(suffix):\n",
    "                list_of_10ks.append(\"https://www.sec.gov\"+ url)\n",
    "                print(\"https://www.sec.gov\"+ url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a178535a-5611-4a51-8a1d-0ab12716395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3f0b6c-a273-405e-ab46-e8ca13a8d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will scrap the 10k report \n",
    "# import chromedriver_binary  # Adds chromedriver binary to path\n",
    "\n",
    "\n",
    "def scrap10k(url, cik, company):\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2) # give browser some time to load the js \n",
    "\n",
    "    html = driver.page_source\n",
    "    sp = BeautifulSoup(html)\n",
    "    \n",
    "    text = \"\"\n",
    "    for d in sp.find_all(text=True):\n",
    "        text += d.get_text()\n",
    "    \n",
    "    # cleaning \n",
    "    # print(text)\n",
    "    text = text.replace(u'\\xa0', u' ').lower()\n",
    "                \n",
    "    # extract risk factor sections only\n",
    "    # print(url)\n",
    "    \n",
    "    # get fiscal year     \n",
    "    yr = \"\"\n",
    "    for span in sp.find_all(text=True):\n",
    "        stext = span.text\n",
    "        if (stext.find(\"January\") != -1\n",
    "         or stext.find(\"February\") != -1\n",
    "         or stext.find(\"March\") != -1\n",
    "         or stext.find(\"April\") != -1\n",
    "         or stext.find(\"May\") != -1\n",
    "         or stext.find(\"June\") != -1\n",
    "         or stext.find(\"July\") != -1\n",
    "         or stext.find(\"August\") != -1\n",
    "         or stext.find(\"September\") != -1\n",
    "         or stext.find(\"October\") != -1\n",
    "         or stext.find(\"November\") != -1\n",
    "         or stext.find(\"December\") != -1):\n",
    "            stext = stext.strip()\n",
    "            yr = stext[-4:]\n",
    "            # print(yr)\n",
    "            break\n",
    "\n",
    "    # print(\"=================\")    \n",
    "    # print(text)\n",
    "\n",
    "    start = find_nth(text, \"item 1a.\", 2)\n",
    "    # print(\"start index\", start)\n",
    "    end = find_nth(text, \"item 1b.\", 2)\n",
    "    # print(\"end index\", end)\n",
    "    substring = text[start:end]\n",
    "    if len(substring) > 0:\n",
    "        risks.append(substring)\n",
    "        years.append(yr)\n",
    "        ciks.append(cik)\n",
    "        urls.append(url)\n",
    "        companies.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87a4587-f17a-42e9-8ef1-561e959acd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataByCIK(cik, company):\n",
    "    ########################################\n",
    "    ### Step 1. Scraping the SEC Query Page\n",
    "    ########################################\n",
    "    # define our parameters dictionary\n",
    "    param_dict = {'action':'getcompany',\n",
    "                  # 'CIK':'1318605', # Tesla\n",
    "                  # 'CIK':'320193', # Apple\n",
    "                  'CIK': cik, # Amazon\n",
    "                  'type':'10-k',\n",
    "                  'dateb':'20230101',\n",
    "                  'owner':'exclude',\n",
    "                  'start':'',\n",
    "                  'output':'',\n",
    "                  'count':'100'}\n",
    "\n",
    "    # request the url, and then parse the response.\n",
    "    response = requests.get(url = endpoint, params = param_dict, headers=header)\n",
    "    # response = requests.get(url = endpoint, params = param_dict)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # print('Request Successful')\n",
    "    # print(response.url)\n",
    "    \n",
    "    doc_table = soup.find_all(class_ = \"blueRow\")\n",
    "    \n",
    "    data = soup.find_all(class_='blueRow')\n",
    "\n",
    "    list_10k = []\n",
    "\n",
    "    for i, row in enumerate(data): \n",
    "        for a in data[i].find_all('a', href=True):\n",
    "            url = a['href']\n",
    "            if (url.startswith('/Archives/edgar/')):\n",
    "                list_10k.append(\"https://www.sec.gov\"+ url)\n",
    "                # print(\"https://www.sec.gov\"+ url)\n",
    "                \n",
    "    ########################################\n",
    "    ### Step 2. Scraping Company Page \n",
    "    ########################################\n",
    "    \n",
    "    list_of_links = []\n",
    "    for link in list_10k:\n",
    "        list_of_links.append(get10kPages(link))\n",
    "        \n",
    "    # get the url for 10k report \n",
    "    list_of_10ks = []\n",
    "    for url in list_of_links:\n",
    "        get10kLinks(url, list_of_10ks)\n",
    "        \n",
    "\n",
    "    ########################################\n",
    "    ### Step 3. Scraping 10k Reports \n",
    "    ########################################\n",
    "    for report in list_of_10ks:\n",
    "        scrap10k(report, cik, company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18cefe-90ab-4169-adba-0b326ae380fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133580b4-c024-4272-8ee6-89212be52158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28338dab-4493-4e84-b69a-e7a699b0b58d",
   "metadata": {},
   "source": [
    "### Run scripts for all the companies of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730751e-d1ad-40a1-8408-e69f64ea0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, row in list_cik.iterrows():\n",
    "    getDataByCIK(row.cik, row.company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41ce53-239b-4cd0-ab37-b6fdd856264a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5dfa4-10b1-48fc-8739-979a51afa674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704f04d-483b-46ad-b6ec-eb91717f17ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98e58dc-f2ac-4712-9dbf-7efb813c0ef1",
   "metadata": {},
   "source": [
    "### Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1777126e-d3c3-4586-9c12-c97d10a778b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame\n",
    "data_tuples = list(zip(ciks, companies, years, risks, urls))\n",
    "# data_tuples\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['cik', 'company', 'fiscal_year', 'risk', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3897e23-fa28-4953-b5fe-de54cf3a7e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>company</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>risk</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320193</td>\n",
       "      <td>aapl</td>\n",
       "      <td>ers.</td>\n",
       "      <td>item 1a.    risk factorsthe following discussi...</td>\n",
       "      <td>https://www.sec.gov/ix?doc=/Archives/edgar/dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320193</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2018</td>\n",
       "      <td>item 1a.risk factorsthe following discussion o...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/320193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320193</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2016</td>\n",
       "      <td>item 1a. risk factorsthe following discussion ...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/320193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320193</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2014</td>\n",
       "      <td>item 1a.\\nrisk factors  the following discussi...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/320193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320193</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2007</td>\n",
       "      <td>item 1a. risk factors\\n</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/320193...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cik company fiscal_year  \\\n",
       "0  320193    aapl        ers.   \n",
       "1  320193    aapl        2018   \n",
       "2  320193    aapl        2016   \n",
       "3  320193    aapl        2014   \n",
       "4  320193    aapl        2007   \n",
       "\n",
       "                                                risk  \\\n",
       "0  item 1a.    risk factorsthe following discussi...   \n",
       "1  item 1a.risk factorsthe following discussion o...   \n",
       "2  item 1a. risk factorsthe following discussion ...   \n",
       "3  item 1a.\\nrisk factors  the following discussi...   \n",
       "4                            item 1a. risk factors\\n   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.sec.gov/ix?doc=/Archives/edgar/dat...  \n",
       "1  https://www.sec.gov/Archives/edgar/data/320193...  \n",
       "2  https://www.sec.gov/Archives/edgar/data/320193...  \n",
       "3  https://www.sec.gov/Archives/edgar/data/320193...  \n",
       "4  https://www.sec.gov/Archives/edgar/data/320193...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d330b0c-1d36-4f05-b6b7-f89f213ffd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7e012-c449-46e5-985c-f247756ef6e7",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876c91a-f354-492b-93ea-b7bf28ca8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unicodedata\n",
    "\n",
    "# text = unicodedata.normalize('NFKD', text.replace(\"\\'\", \"'\").replace(\"\\ in\\ form\", \" inform\").replace(\"\\n\", \" \").lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ccb73-f5aa-4ec8-bda8-7f1b9a733d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text)\n",
    "# dev_docs = [doc for doc in text.split('\\n')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017bad0-3ee7-4af5-8707-52b39f4c85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from   nltk.corpus import stopwords\n",
    "# import string\n",
    "\n",
    "# # Making stopwords list\n",
    "# stoplist = stopwords.words('english')\n",
    "# for el in [i for i in string.punctuation]:\n",
    "#     stoplist.append(el)\n",
    "\n",
    "# # Set up vectorizer\n",
    "# vectorizer = TfidfVectorizer(\n",
    "#     encoding='utf-8',\n",
    "#     min_df=1, # include words that occur in as few as a single document, 1 = a single document\n",
    "#     max_df=1.0, # include words that occur in as many as all documents, 1.0 = 100% = all documents\n",
    "#      binary=False,\n",
    "#     norm='l2',\n",
    "#     stop_words = stoplist,\n",
    "#     use_idf=True\n",
    "# )\n",
    "\n",
    "# X = vectorizer.fit_transform(dev_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759c23d-d355-4f57-a2c9-653ee13a39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0756e-fd23-448a-b96a-0b72c7689a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eee20d-1bc0-4e39-85c7-8c2df0df10ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4035e7-6423-4913-af9c-8f3354fc5d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24f1ed-aa87-4643-a60c-9dfdd411f9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "507fb132-104d-40d9-8688-acc352dcc613",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://stackoverflow.com/questions/1883980/find-the-nth-occurrence-of-substring-in-a-string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
