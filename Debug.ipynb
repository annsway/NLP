{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343ffc2c-667c-48fe-83a5-7d34dc140a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import simplejson as json\n",
    "from urllib.request import Request, urlopen\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from   sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from   sklearn.model_selection import cross_val_score\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from   sklearn.cluster import KMeans, SpectralClustering, DBSCAN, OPTICS, AgglomerativeClustering\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "from   collections import defaultdict\n",
    "from   nltk.corpus import stopwords\n",
    "from   sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from wordcloud import WordCloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13104cd-7be6-47dd-b84a-77c01c21bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'cik': ['123'], 'symbol': ['test'], 'company': ['apple'], 'fiscal_year': '2018', 'risk': 'abandon', 'url': 'none', 'price': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d776a5d7-6fdf-4d3c-bcf4-45b8ebc29ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(test)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76eef65a-31df-42f4-811f-4602ca42b65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>symbol</th>\n",
       "      <th>company</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>risk</th>\n",
       "      <th>url</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>test</td>\n",
       "      <td>apple</td>\n",
       "      <td>2018</td>\n",
       "      <td>abandon</td>\n",
       "      <td>none</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cik symbol company fiscal_year     risk   url  price\n",
       "0  123   test   apple        2018  abandon  none    100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81aac984-aa4d-4698-b7ed-5008e653d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making stopwords list\n",
    "stoplist = stopwords.words('english')\n",
    "for el in [i for i in string.punctuation]:\n",
    "    stoplist.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac111c6-ecbb-46d9-b414-767b66b44571",
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_file = os.path.join('emolex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823a5952-1358-4d5b-97e7-5f2c2450bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_emolex function from INFO 3350 problem set code\n",
    "\n",
    "emolex_file = os.path.join('emolex.txt')\n",
    "\n",
    "def read_emolex(filepath=None):\n",
    "    '''\n",
    "    Takes a file path to the emolex lexicon file.\n",
    "    Returns a dictionary of emolex sentiment values.\n",
    "    '''\n",
    "    if filepath==None: # Try to find the emolex file\n",
    "        filepath = os.path.join('emolex.txt')\n",
    "        if os.path.isfile(filepath):\n",
    "            pass\n",
    "        elif os.path.isfile('emolex.txt'):\n",
    "            filepath = 'emolex.txt'\n",
    "        else:\n",
    "            raise FileNotFoundError('No EmoLex file found')\n",
    "    emolex = defaultdict(dict) # Like Counter(), defaultdict eases dictionary creation\n",
    "    with open(filepath, 'r') as f:\n",
    "    # emolex file format is: word emotion value\n",
    "        for line in f:\n",
    "            word, emotion, value = line.strip().split()\n",
    "            emolex[word][emotion] = int(value)\n",
    "    return emolex\n",
    "\n",
    "# Get EmoLex data. Make sure you set the right file path above.\n",
    "emolex = read_emolex(emolex_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7983d027-10a5-42f0-b065-64d3b7150f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get EmoLex df. Make sure you set the right file path above.\n",
    "emolex = read_emolex(emolex_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36dbba3e-774c-46ca-b3b0-a47a6b0d4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentScore(sentence_dicts, df, index):\n",
    "    \n",
    "    bookdict = dict({'anger': 0 , 'anticipation': 0,'disgust': 0,'fear': 0,'joy': 0,'negative': 0,'positive': 0,'sadness': 0,'surprise': 0, 'trust': 0})\n",
    "    \n",
    "    for sentence_dict in sentence_dicts:\n",
    "        for emotion in sentence_dict:\n",
    "            bookdict[emotion] += sentence_dict[emotion]\n",
    "    \n",
    "    for emotion in bookdict.keys():\n",
    "        bookdict[emotion] /= len(sentence_dicts)\n",
    "        df.at[index, emotion] = bookdict[emotion]\n",
    "    \n",
    "    return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a54adce6-9e6e-4e2e-8f63-1843ea30257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text, stops=[]):\n",
    "    sentences = []\n",
    "    for sent in sent_tokenize(text.lower()):\n",
    "        sentences.append([word for word in word_tokenize(sent) if word not in stops])\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35193a0-65b4-4af6-a065-268bce3de692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_sentiment_score from INFO 3350 problem set code\n",
    "def sentence_sentiment_score(toks, lexicon = emolex):\n",
    "    print(\"input sentences: \", toks)\n",
    "    total = 0\n",
    "    emo_dict = defaultdict(lambda: 0)\n",
    "    \n",
    "    emotions = ['anger', 'anticipation','disgust','fear','joy','negative','positive','sadness','surprise', 'trust']\n",
    "    \n",
    "    \n",
    "    for word in toks:\n",
    "        print(\"for ====\", word)\n",
    "        total += 1\n",
    "        print(lexicon[word])\n",
    "        for emotion in emotions:\n",
    "            try:\n",
    "                emo_dict[emotion] += lexicon[word][emotion]\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        if total > 0:\n",
    "            emo_dict[emotion] /= total\n",
    "        \n",
    "    return emo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145fee88-f52f-4e3f-bef8-c330cd00bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding sentiment score columns\n",
    "size = len(df)\n",
    "\n",
    "df['anger'] = np.zeros(size)\n",
    "df['anticipation'] = np.zeros(size)\n",
    "df['disgust'] = np.zeros(size)\n",
    "df['fear'] = np.zeros(size)\n",
    "df['joy'] = np.zeros(size)\n",
    "df['negative'] = np.zeros(size)\n",
    "df['positive'] = np.zeros(size)\n",
    "df['sadness'] = np.zeros(size)\n",
    "df['surprise'] = np.zeros(size)\n",
    "df['trust'] = np.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93c28e1a-79af-4491-86d6-b2b954142499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0596251-aed7-4e6a-8fb0-6a7b70bc19b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abandon\n",
      "++++ [['abandon']]\n",
      "input sentences:  ['abandon']\n",
      "for ==== abandon\n",
      "{'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}\n",
      "CPU times: user 7.92 ms, sys: 2.65 ms, total: 10.6 ms\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, text in enumerate(df['risk']):\n",
    "    sentence_dicts = []\n",
    "    for sentence in tokenize_text(text, stops=stoplist):\n",
    "        # print(sentence)\n",
    "        sentence_dicts.append(sentence_sentiment_score(sentence))\n",
    "        # print(sentence_dicts)\n",
    "    # print(len(sentence_dicts))\n",
    "    # print(index)\n",
    "    getSentScore(sentence_dicts, df, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3220773-f2f7-4415-8568-175e08a1fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>symbol</th>\n",
       "      <th>company</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>risk</th>\n",
       "      <th>url</th>\n",
       "      <th>price</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>test</td>\n",
       "      <td>apple</td>\n",
       "      <td>2018</td>\n",
       "      <td>abandon</td>\n",
       "      <td>none</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cik symbol company fiscal_year     risk   url  price  anger  anticipation  \\\n",
       "0  123   test   apple        2018  abandon  none    100    0.0           0.0   \n",
       "\n",
       "   disgust  fear  joy  negative  positive  sadness  surprise  trust  \n",
       "0      0.0   1.0  0.0       1.0       0.0      1.0       0.0    0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa0462d-15a7-4e28-bb0a-306676f0c08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
